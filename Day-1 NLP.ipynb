{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5748ddd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\91918\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Tokens:\n",
      "['Mary', 'jumps', 'in', 'a', 'field', 'and', 'following', 'her', 'Sam', 'also', 'jumped', '.', 'That', 'our', 'lives', 'would', 'be', 'changed', 'forever', '.', 'The', 'world', 'was', 'loud', 'with', 'carnage', 'and', 'sirens', 'and', 'then', 'quiet', 'with', 'missing', 'voices', 'that', 'would', 'never', 'be', 'heard', 'again', '.', 'These', 'lives', 'remain', 'precious', 'to', 'our', 'country', 'and', 'infinitely', 'precious', 'to', 'many', 'of', 'you', '.', 'Today', ',', 'we', 'remember', 'your', 'loss', ',', 'we', 'share', 'your', 'sorrow', ',', 'and', 'we', 'honor', 'the', 'men', 'and', 'women', 'you', 'have', 'loved', 'so', 'long', 'and', 'so', 'well', '.', 'For', 'those', 'too', 'young', 'to', 'recall', 'that', 'clear', 'September', 'day', ',', 'it', 'is', 'hard', 'to', 'describe', 'the', 'mix', 'of', 'feelings', 'we', 'experienced', '.']\n"
     ]
    }
   ],
   "source": [
    "#1. Write a Python script that takes a paragraph of text and performs word tokenization using NLTK. Print the list of tokens\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download the required NLTK data\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Sample text\n",
    "text = \"\"\"\n",
    "Mary jumps in a field and following her Sam also jumped.\n",
    "That our lives would be changed forever. The world was loud with carnage and sirens and then quiet with missing voices that would never be heard again.\n",
    "These lives remain precious to our country and infinitely precious to many of you. Today, we remember your loss, we share your sorrow, and we honor the men and women you have loved so long and so well. For those too young to recall that clear September day, it is hard to describe the mix of feelings we experienced.\n",
    "\"\"\"\n",
    "\n",
    "# Tokenization\n",
    "tokens = word_tokenize(text)\n",
    "print(\"Word Tokens:\")\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd358ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\91918\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "POS Tags:\n",
      "[('Mary', 'NNP'), ('jumps', 'NNS'), ('in', 'IN'), ('a', 'DT'), ('field', 'NN'), ('and', 'CC'), ('following', 'VBG'), ('her', 'PRP$'), ('Sam', 'NNP'), ('also', 'RB'), ('jumped', 'VBD'), ('.', '.'), ('That', 'IN'), ('our', 'PRP$'), ('lives', 'NNS'), ('would', 'MD'), ('be', 'VB'), ('changed', 'VBN'), ('forever', 'RB'), ('.', '.'), ('The', 'DT'), ('world', 'NN'), ('was', 'VBD'), ('loud', 'JJ'), ('with', 'IN'), ('carnage', 'NN'), ('and', 'CC'), ('sirens', 'NNS'), ('and', 'CC'), ('then', 'RB'), ('quiet', 'JJ'), ('with', 'IN'), ('missing', 'VBG'), ('voices', 'NNS'), ('that', 'WDT'), ('would', 'MD'), ('never', 'RB'), ('be', 'VB'), ('heard', 'RB'), ('again', 'RB'), ('.', '.'), ('These', 'DT'), ('lives', 'NNS'), ('remain', 'VBP'), ('precious', 'JJ'), ('to', 'TO'), ('our', 'PRP$'), ('country', 'NN'), ('and', 'CC'), ('infinitely', 'RB'), ('precious', 'JJ'), ('to', 'TO'), ('many', 'JJ'), ('of', 'IN'), ('you', 'PRP'), ('.', '.'), ('Today', 'NN'), (',', ','), ('we', 'PRP'), ('remember', 'VBP'), ('your', 'PRP$'), ('loss', 'NN'), (',', ','), ('we', 'PRP'), ('share', 'NN'), ('your', 'PRP$'), ('sorrow', 'NN'), (',', ','), ('and', 'CC'), ('we', 'PRP'), ('honor', 'VBP'), ('the', 'DT'), ('men', 'NNS'), ('and', 'CC'), ('women', 'NNS'), ('you', 'PRP'), ('have', 'VBP'), ('loved', 'VBN'), ('so', 'RB'), ('long', 'RB'), ('and', 'CC'), ('so', 'RB'), ('well', 'RB'), ('.', '.'), ('For', 'IN'), ('those', 'DT'), ('too', 'RB'), ('young', 'JJ'), ('to', 'TO'), ('recall', 'VB'), ('that', 'DT'), ('clear', 'JJ'), ('September', 'NNP'), ('day', 'NN'), (',', ','), ('it', 'PRP'), ('is', 'VBZ'), ('hard', 'JJ'), ('to', 'TO'), ('describe', 'VB'), ('the', 'DT'), ('mix', 'NN'), ('of', 'IN'), ('feelings', 'NNS'), ('we', 'PRP'), ('experienced', 'VBD'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "#2. Write a Python script that performs POS tagging on a list of tokens using NLTK.\n",
    "#Print the list of tuples containing the word and its POS tag\n",
    "\n",
    "from nltk import pos_tag\n",
    "\n",
    "# Download the required NLTK data for POS tagging\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# POS tagging\n",
    "pos_tags = pos_tag(tokens)\n",
    "print(\"\\nPOS Tags:\")\n",
    "print(pos_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3262d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stemmed Words:\n",
      "['mari', 'jump', 'in', 'a', 'field', 'and', 'follow', 'her', 'sam', 'also', 'jump', '.', 'that', 'our', 'live', 'would', 'be', 'chang', 'forev', '.', 'the', 'world', 'wa', 'loud', 'with', 'carnag', 'and', 'siren', 'and', 'then', 'quiet', 'with', 'miss', 'voic', 'that', 'would', 'never', 'be', 'heard', 'again', '.', 'these', 'live', 'remain', 'preciou', 'to', 'our', 'countri', 'and', 'infinit', 'preciou', 'to', 'mani', 'of', 'you', '.', 'today', ',', 'we', 'rememb', 'your', 'loss', ',', 'we', 'share', 'your', 'sorrow', ',', 'and', 'we', 'honor', 'the', 'men', 'and', 'women', 'you', 'have', 'love', 'so', 'long', 'and', 'so', 'well', '.', 'for', 'those', 'too', 'young', 'to', 'recal', 'that', 'clear', 'septemb', 'day', ',', 'it', 'is', 'hard', 'to', 'describ', 'the', 'mix', 'of', 'feel', 'we', 'experienc', '.']\n"
     ]
    }
   ],
   "source": [
    "#3.Write a Python script that applies stemming to a list of words \n",
    "#using NLTK's Porter Stemmer. Print the list of stemmed words\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Initialize the Porter Stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Apply stemming\n",
    "stemmed_words = [stemmer.stem(word) for word in tokens]\n",
    "print(\"\\nStemmed Words:\")\n",
    "print(stemmed_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca79b56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\91918\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\91918\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lemmatized Words:\n",
      "['Mary', 'jump', 'in', 'a', 'field', 'and', 'following', 'her', 'Sam', 'also', 'jumped', '.', 'That', 'our', 'life', 'would', 'be', 'changed', 'forever', '.', 'The', 'world', 'wa', 'loud', 'with', 'carnage', 'and', 'siren', 'and', 'then', 'quiet', 'with', 'missing', 'voice', 'that', 'would', 'never', 'be', 'heard', 'again', '.', 'These', 'life', 'remain', 'precious', 'to', 'our', 'country', 'and', 'infinitely', 'precious', 'to', 'many', 'of', 'you', '.', 'Today', ',', 'we', 'remember', 'your', 'loss', ',', 'we', 'share', 'your', 'sorrow', ',', 'and', 'we', 'honor', 'the', 'men', 'and', 'woman', 'you', 'have', 'loved', 'so', 'long', 'and', 'so', 'well', '.', 'For', 'those', 'too', 'young', 'to', 'recall', 'that', 'clear', 'September', 'day', ',', 'it', 'is', 'hard', 'to', 'describe', 'the', 'mix', 'of', 'feeling', 'we', 'experienced', '.']\n"
     ]
    }
   ],
   "source": [
    "#• 4. Write a Python script that applies lemmatization to a \n",
    "#list of words using NLTK's WordNet Lemmatize. Print the list of lemmatized words.\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download the required NLTK data for lemmatization\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Initialize the WordNet Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Apply lemmatization\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "print(\"\\nLemmatized Words:\")\n",
    "print(lemmatized_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71af45ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Tokens:\n",
      "['Mary', 'jumps', 'in', 'a', 'field', 'and', 'following', 'her', 'Sam', 'also', 'jumped', '.', 'That', 'our', 'lives', 'would', 'be', 'changed', 'forever', '.', 'The', 'world', 'was', 'loud', 'with', 'carnage', 'and', 'sirens', 'and', 'then', 'quiet', 'with', 'missing', 'voices', 'that', 'would', 'never', 'be', 'heard', 'again', '.', 'These', 'lives', 'remain', 'precious', 'to', 'our', 'country', 'and', 'infinitely', 'precious', 'to', 'many', 'of', 'you', '.', 'Today', ',', 'we', 'remember', 'your', 'loss', ',', 'we', 'share', 'your', 'sorrow', ',', 'and', 'we', 'honor', 'the', 'men', 'and', 'women', 'you', 'have', 'loved', 'so', 'long', 'and', 'so', 'well', '.', 'For', 'those', 'too', 'young', 'to', 'recall', 'that', 'clear', 'September', 'day', ',', 'it', 'is', 'hard', 'to', 'describe', 'the', 'mix', 'of', 'feelings', 'we', 'experienced', '.']\n",
      "\n",
      "POS Tags:\n",
      "[('Mary', 'NNP'), ('jumps', 'NNS'), ('in', 'IN'), ('a', 'DT'), ('field', 'NN'), ('and', 'CC'), ('following', 'VBG'), ('her', 'PRP$'), ('Sam', 'NNP'), ('also', 'RB'), ('jumped', 'VBD'), ('.', '.'), ('That', 'IN'), ('our', 'PRP$'), ('lives', 'NNS'), ('would', 'MD'), ('be', 'VB'), ('changed', 'VBN'), ('forever', 'RB'), ('.', '.'), ('The', 'DT'), ('world', 'NN'), ('was', 'VBD'), ('loud', 'JJ'), ('with', 'IN'), ('carnage', 'NN'), ('and', 'CC'), ('sirens', 'NNS'), ('and', 'CC'), ('then', 'RB'), ('quiet', 'JJ'), ('with', 'IN'), ('missing', 'VBG'), ('voices', 'NNS'), ('that', 'WDT'), ('would', 'MD'), ('never', 'RB'), ('be', 'VB'), ('heard', 'RB'), ('again', 'RB'), ('.', '.'), ('These', 'DT'), ('lives', 'NNS'), ('remain', 'VBP'), ('precious', 'JJ'), ('to', 'TO'), ('our', 'PRP$'), ('country', 'NN'), ('and', 'CC'), ('infinitely', 'RB'), ('precious', 'JJ'), ('to', 'TO'), ('many', 'JJ'), ('of', 'IN'), ('you', 'PRP'), ('.', '.'), ('Today', 'NN'), (',', ','), ('we', 'PRP'), ('remember', 'VBP'), ('your', 'PRP$'), ('loss', 'NN'), (',', ','), ('we', 'PRP'), ('share', 'NN'), ('your', 'PRP$'), ('sorrow', 'NN'), (',', ','), ('and', 'CC'), ('we', 'PRP'), ('honor', 'VBP'), ('the', 'DT'), ('men', 'NNS'), ('and', 'CC'), ('women', 'NNS'), ('you', 'PRP'), ('have', 'VBP'), ('loved', 'VBN'), ('so', 'RB'), ('long', 'RB'), ('and', 'CC'), ('so', 'RB'), ('well', 'RB'), ('.', '.'), ('For', 'IN'), ('those', 'DT'), ('too', 'RB'), ('young', 'JJ'), ('to', 'TO'), ('recall', 'VB'), ('that', 'DT'), ('clear', 'JJ'), ('September', 'NNP'), ('day', 'NN'), (',', ','), ('it', 'PRP'), ('is', 'VBZ'), ('hard', 'JJ'), ('to', 'TO'), ('describe', 'VB'), ('the', 'DT'), ('mix', 'NN'), ('of', 'IN'), ('feelings', 'NNS'), ('we', 'PRP'), ('experienced', 'VBD'), ('.', '.')]\n",
      "\n",
      "Stemmed Words:\n",
      "['mari', 'jump', 'in', 'a', 'field', 'and', 'follow', 'her', 'sam', 'also', 'jump', '.', 'that', 'our', 'live', 'would', 'be', 'chang', 'forev', '.', 'the', 'world', 'wa', 'loud', 'with', 'carnag', 'and', 'siren', 'and', 'then', 'quiet', 'with', 'miss', 'voic', 'that', 'would', 'never', 'be', 'heard', 'again', '.', 'these', 'live', 'remain', 'preciou', 'to', 'our', 'countri', 'and', 'infinit', 'preciou', 'to', 'mani', 'of', 'you', '.', 'today', ',', 'we', 'rememb', 'your', 'loss', ',', 'we', 'share', 'your', 'sorrow', ',', 'and', 'we', 'honor', 'the', 'men', 'and', 'women', 'you', 'have', 'love', 'so', 'long', 'and', 'so', 'well', '.', 'for', 'those', 'too', 'young', 'to', 'recal', 'that', 'clear', 'septemb', 'day', ',', 'it', 'is', 'hard', 'to', 'describ', 'the', 'mix', 'of', 'feel', 'we', 'experienc', '.']\n",
      "\n",
      "Lemmatized Words:\n",
      "['Mary', 'jump', 'in', 'a', 'field', 'and', 'following', 'her', 'Sam', 'also', 'jumped', '.', 'That', 'our', 'life', 'would', 'be', 'changed', 'forever', '.', 'The', 'world', 'wa', 'loud', 'with', 'carnage', 'and', 'siren', 'and', 'then', 'quiet', 'with', 'missing', 'voice', 'that', 'would', 'never', 'be', 'heard', 'again', '.', 'These', 'life', 'remain', 'precious', 'to', 'our', 'country', 'and', 'infinitely', 'precious', 'to', 'many', 'of', 'you', '.', 'Today', ',', 'we', 'remember', 'your', 'loss', ',', 'we', 'share', 'your', 'sorrow', ',', 'and', 'we', 'honor', 'the', 'men', 'and', 'woman', 'you', 'have', 'loved', 'so', 'long', 'and', 'so', 'well', '.', 'For', 'those', 'too', 'young', 'to', 'recall', 'that', 'clear', 'September', 'day', ',', 'it', 'is', 'hard', 'to', 'describe', 'the', 'mix', 'of', 'feeling', 'we', 'experienced', '.']\n"
     ]
    }
   ],
   "source": [
    "#• 5. Write a Python script that combines word tokenization, POS tagging, stemming, and lemmatization. \n",
    "#Print the results at each step for a given paragraph of text\n",
    "# Tokenization\n",
    "tokens = word_tokenize(text)\n",
    "print(\"Word Tokens:\")\n",
    "print(tokens)\n",
    "\n",
    "# POS Tagging\n",
    "pos_tags = pos_tag(tokens)\n",
    "print(\"\\nPOS Tags:\")\n",
    "print(pos_tags)\n",
    "\n",
    "# Stemming\n",
    "stemmed_words = [stemmer.stem(word) for word in tokens]\n",
    "print(\"\\nStemmed Words:\")\n",
    "print(stemmed_words)\n",
    "\n",
    "# Lemmatization\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "print(\"\\nLemmatized Words:\")\n",
    "print(lemmatized_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0040d4f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
